{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iris data set /Random Process.ipynb",
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1Vqm6vwvtFWkcC_q0R1fX8PXjURv-pAzl",
      "authorship_tag": "ABX9TyMHBh9EFQ5HVS9mCkz4u8vt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satyambhatt5/Data_science/blob/main/iris_data_set_Random_Process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Atoa1dlBc4ZV"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm2eNvXJdLXb"
      },
      "source": [
        "**Heart data set Random Forest classifier **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFWnh10Bdmmr"
      },
      "source": [
        "iris=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Practice Data Set/Iris.csv\")\r\n",
        "iris.head()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhmqMb1B8wOd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoXDU3bDt3ii"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7N64OVd8yzj"
      },
      "source": [
        "od=OrdinalEncoder()\r\n",
        "y=od.fit_transform(iris[['Species']])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0fYeqRneOPM"
      },
      "source": [
        "#ohe = OneHotEncoder(sparse=False)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG1OzE-szoLz"
      },
      "source": [
        "#y=ohe.fit_transform(iris[['Species']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li_5_h6V8umB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4fFHzrY05xs"
      },
      "source": [
        "X=iris.iloc[:,1:5]\r\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkXkuHHaeoaK"
      },
      "source": [
        "#spliting the data \r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBQ7llj5ffIm"
      },
      "source": [
        "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.20,random_state=42)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgtxWnspf1KY"
      },
      "source": [
        "X_train.shape,y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2h3xrNC2OPw"
      },
      "source": [
        "X_test.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EySk5kP2buP"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_niN_nhU2v6C"
      },
      "source": [
        "sc=StandardScaler()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf7uwIwS3GV8"
      },
      "source": [
        "#FOR THE TRIAN SET WE WILL USE ONLY THE FIT_TRANSFORM\r\n",
        "\r\n",
        "X_train = sc.fit_transform(X_train)\r\n",
        "\r\n",
        "#FOR THE TEST SET USE ONLY TRANSFROM\r\n",
        "\r\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCWVFE8H3cxh"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81ihQ6TM3ewa"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyRt-bgZ337x"
      },
      "source": [
        "# Fitting Random Forest Classification to the Training set\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "\r\n",
        "classifier = RandomForestClassifier(n_estimators = 50, criterion = 'entropy', random_state = 0)\r\n",
        "classifier.fit(X_train, y_train)\r\n",
        "\r\n",
        "# max_depth/ verbose = Ayush - For prunning | \r\n",
        "\r\n",
        "# max_features= Aditya | AUTO \r\n",
        "\r\n",
        "# max_leaf_nodes= Kajal | Max number of leaf Nodes | \r\n",
        "\r\n",
        "# min_samples_leaf= Gurpreet | Min number of rows required to be a leaf node*\r\n",
        "\r\n",
        "# min_samples_split=  Lakshya | Min number of rows required to split a node further*\r\n",
        "\r\n",
        "\r\n",
        "# n_estimators= Surya\r\n",
        "\r\n",
        "# n_job = -1 \r\n",
        "#____________________________________________________________\r\n",
        "# oob_score= Ankit | is a way to validate the RF M | Out of BAG*  \r\n",
        "  \r\n",
        "                     # N3 of correctly predicted rows "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcKkvGdl39oR"
      },
      "source": [
        "# I can also think of applying the GRIDSEARCH for RANDOM FOREST\r\n",
        "# so as to find the optimal values of some arguments to fine tune to performance of\r\n",
        "# Random FOrest\r\n",
        "\r\n",
        "\r\n",
        "pargrid_rf = {'n_estimators': [70, 80, 90, 100, 120, 150, 200],'max_features': [5]}\r\n",
        "\r\n",
        "gscv_rf = GridSearchCV(estimator = RandomForestClassifier(), \r\n",
        "                        param_grid = pargrid_rf, \r\n",
        "                        cv = 5,\r\n",
        "                        verbose = True, \r\n",
        "                        n_jobs = -1)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZiQnE0I4Q_Y"
      },
      "source": [
        "gscv_results = gscv_rf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgtML54K6sPZ"
      },
      "source": [
        "# Predicting the Test set results\r\n",
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjHUj14e7_Ap"
      },
      "source": [
        "# Making the Confusion Matrix\r\n",
        "from sklearn.metrics import confusion_matrix,classification,classification_report,ConfusionMatrixDisplay\r\n",
        "cm = confusion_matrix(y_test, y_pred)\r\n",
        "cm\r\n",
        "\r\n",
        "# Find the Accuracy and AUC ROC of the confusion matrix and compare that with Training result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8ZaAyqw_Ak7"
      },
      "source": [
        "cl_report =classification_report(y_test,y_pred,)\r\n",
        "cl_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaN_DR8h8FEA"
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GCK7fC0-CIR"
      },
      "source": [
        "accuracy =accuracy_score(y_test,y_pred)\r\n",
        "accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCYhmHLi-mnl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}