{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Categorical Feature Encoding Challenge how to work with categorical data  II.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1QUtD14XJhpVn8249M9n0oUstQv5PxowC",
      "authorship_tag": "ABX9TyMbc/xyNMZdvJCTN1xnESsS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satyambhatt5/Data_science/blob/main/Categorical_Feature_Encoding_Challenge_how_to_work_with_categorical_data_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbUcbq_8Oeya"
      },
      "source": [
        "!mkdir -p /root/.kaggle/\r\n",
        "!mv kaggle.json /root/.kaggle/\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxTXevKmP-n8"
      },
      "source": [
        "import kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5AO0VdPQA-Z"
      },
      "source": [
        "!kaggle competitions download -c cat-in-the-dat-ii"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFOYBL24QYqs"
      },
      "source": [
        "!unzip train.csv.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYmJiClRQgA7"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Mu_9_nnQwPF"
      },
      "source": [
        "ch=pd.read_csv(\"/content/train.csv\")\r\n",
        "ch.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnD0zE-8Q5U5"
      },
      "source": [
        "ch.info()\r\n",
        "ch.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4Sd9jVHRy6o"
      },
      "source": [
        "#this data consist the all kind of the categorical value \r\n",
        "\r\n",
        "#NOMINAL\r\n",
        "#ORDINAL\r\n",
        "#CYLIC\r\n",
        "#BINARY \r\n",
        "\r\n",
        "#IT IS BINARY CLASSIFICATION MODEL\r\n",
        "\r\n",
        "#HERE TOTAL\r\n",
        "\r\n",
        "#BINARY VARIABLE =5   \r\n",
        "#NOMINAL VARIABLE=10 #TWO ARE MORE CATEGORY VALUE WHICH DO NOT HAVE ANY ORDER IN THAT LIKE   GENDER \r\n",
        "#ORDINAL VARIABLE =6 #CATEGORY WHICH HAVE PARTICULAR ORDER WITH THEM WHICH HAVE IMPORTENT MEANING  EX: LOW MEDIUM,HIGH\r\n",
        "#CYLIC = 2 CYLIC VARIABLE THE REAPEAT AFTER FEW DAYS EX: WEEKDAYS   \r\n",
        "#target  VARIBLE  EX: 0 AND 1 \r\n",
        "\r\n",
        "\r\n",
        "#look into the  ord 2 feature they are sevral category \r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNqrXE7NVOTQ"
      },
      "source": [
        "ch.ord_2.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuN_iLBiVUaO"
      },
      "source": [
        "#create a dictionary \r\n",
        "\r\n",
        "mapping= {\"Freezing\":0,\"Warm\":1,\"Cold\":2,\"Boiling Hot\":3,\"Hot\":4,\"Lava Hot\":5}\r\n",
        "mapping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h70aWHQWVlf"
      },
      "source": [
        "ch.loc[:,\"ord_2\"]=ch.ord_2.map(mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-TGgevlXByh"
      },
      "source": [
        "ch.ord_2.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo9K0No3XKcb"
      },
      "source": [
        "#these type encoding we can do through the #       label encoding \r\n",
        "\r\n",
        "chl=pd.read_csv(\"/content/train.csv\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN6u2JCmcQ76"
      },
      "source": [
        "#fill the nan value \r\n",
        "\r\n",
        "from sklearn import preprocessing\r\n",
        "\r\n",
        "chl.loc[:,\"ord_2\"]=chl.ord_2.fillna(\"NONE\")\r\n",
        "chl.ord_2.value_counts()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HWbm_omczeF"
      },
      "source": [
        "#INITILIGE THE LABEL INCODER \r\n",
        "\r\n",
        "lab_enc=preprocessing.LabelEncoder()\r\n",
        "lab_enc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwEWdrMHdtJ-"
      },
      "source": [
        "#fill the label encoder  and ord2 coloum \r\n",
        "#please dont transform the data directly fit and then tranform\r\n",
        "\r\n",
        "chl.loc[:,\"ord_2\"]=lab_enc.fit_transform(chl.ord_2.values)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZf1sjjHe3Fh"
      },
      "source": [
        "chl.ord_2.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63RceD4mf8jG"
      },
      "source": [
        "#here we can see that label encoder does not handle nan value \r\n",
        "\r\n",
        "#here we can use the directly these model but we can use the \r\n",
        "\r\n",
        "#decision tree ,random tree extra tree and \r\n",
        "\r\n",
        "#boosted tree model\r\n",
        "\r\n",
        "#XGBOOST\r\n",
        "#GBM\r\n",
        "#LIGHTGBM\r\n",
        "\r\n",
        "#BUT WE CAN USE THE NEURAL NETWORK,SUPPORT VECTOR MACHINE LINEAR MODEL''\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7GACq72hKPk"
      },
      "source": [
        "#FOR THESE TYPE MODEL WE CAN BINARY THE DATA \r\n",
        "\r\n",
        "#HERE THEY ARE MORE TECHNIQUE TO CONNECT THE DATA IN NUMERICAL DATA \r\n",
        "chl.groupby(['ord_2'])[\"id\"].count()\r\n",
        "ch.groupby(['ord_2'])[\"id\"].count()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0fXme4Jji0R"
      },
      "source": [
        "ch.groupby(['ord_2'])[\"id\"].transform(\"count\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIUENDfckw9q"
      },
      "source": [
        "ch.groupby([\"ord_1\",\"ord_2\"])[\"id\"].count().reset_index(name=\"count\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS8R4zgEld0A"
      },
      "source": [
        "#now we can categorical value in with other new feature value \r\n",
        "\r\n",
        "ch[\"new_feature\"]=(ch.ord_1.astype(str) + \"_\" + ch.ord_2.astype(str))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlydQsrLnXuh"
      },
      "source": [
        "ch.new_feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-Nyucoxni_p"
      },
      "source": [
        "!unzip test.csv.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCOZL_tVo-6g"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "#read the train data \r\n",
        "train=pd.read_csv(\"/content/train.csv\")\r\n",
        "#read the test data \r\n",
        "test =pd.read_csv(\"/content/test.csv\")\r\n",
        "\r\n",
        "\r\n",
        "#now create the fake target colum for the test data \r\n",
        "#since the this coloum does not exit \r\n",
        "test.loc[:,\"target\"] = -1\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5NlkNQApnk8"
      },
      "source": [
        "#adding the both training data into\r\n",
        "data=pd.concat([train,test]).reset_index(drop=True)\r\n",
        "\r\n",
        "#make the list of the target feature \r\n",
        "#id and  target should not be encoded we use the label\r\n",
        "feature=[x for x in train.columns if x not in [\"id\",\"target\"]] \r\n",
        "feature\r\n",
        "\r\n",
        "#now loop over the feature list \r\n",
        "for feat in feature:\r\n",
        "  lab_enc =preprocessing.LabelEncoder()\r\n",
        "\r\n",
        "  #note the tricks here \r\n",
        "  #since the the data categorical so that it is convert into the str \r\n",
        "  #convert the all data type into the string \r\n",
        "  #no matter it is int/float\r\n",
        "  #int/float it is categorical\r\n",
        "  temp_col =data[feat].fillna(\"NONE\").astype(str).values\r\n",
        "\r\n",
        "  #we need to fit and transform the data because we dont have extra test \r\n",
        "\r\n",
        "  data.loc[:,feat]=lab_enc.fit_transform(temp_col)\r\n",
        "\r\n",
        "#split the data train and test so that \r\n",
        "\r\n",
        "train =data[data.target != -1].reset_index(drop=True)\r\n",
        "test=  data[data.target ==-1].reset_index(drop=True)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6yV8-POqqcL"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYeQloD3EW6u"
      },
      "source": [
        "#now we buid the cross validation of the data \r\n",
        "from sklearn.model_selection import KFold,StratifiedKFold\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi3XblvvHgVD"
      },
      "source": [
        "if __name__ == \"__main__\":\r\n",
        "\r\n",
        "  #read the data  \r\n",
        "\r\n",
        "  df =pd.read_csv(\"/content/train.csv\")\r\n",
        "\r\n",
        "  #create the folder Kfold fill with -1\r\n",
        "\r\n",
        "  df[\"kfold\"]=-1\r\n",
        "\r\n",
        "  #next the step randomize the data in row \r\n",
        "  df=df.sample(frac=1).reset_index(drop=True)\r\n",
        "\r\n",
        "  #fetch label\r\n",
        "\r\n",
        "  y=df.target.values\r\n",
        "\r\n",
        "  #initiate the kfold class from model selection \r\n",
        "\r\n",
        "  kf=StratifiedKFold(n_splits=5)\r\n",
        "\r\n",
        "  #filled with kfold coloums \r\n",
        "\r\n",
        "  for f,(t_,v_) in enumerate(kf.split(X=df,y = y)):\r\n",
        "    df.loc[v_,\"kfold\"] =f\r\n",
        "\r\n",
        "  #save the new csv in kfold colum\r\n",
        "\r\n",
        "  df.to_csv(\"//content/drive/MyDrive/Kfold data/fold.csv\",index=False)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80Qgy0lzXVDG"
      },
      "source": [
        "df1 =pd.read_csv(\"/content/drive/MyDrive/Kfold data/fold.csv\")\r\n",
        "print(df1.head())\r\n",
        "df1.kfold.value_counts()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRZv9JW7Za4z"
      },
      "source": [
        "#now we check the target distribution as per fold data is same in cross validation data we need the same thong on the when we buiding the model\r\n",
        "print(df1[df1.kfold==0].target.value_counts())\r\n",
        "print(df1[df1.kfold==1].target.value_counts())\r\n",
        "print(df1[df1.kfold==2].target.value_counts())\r\n",
        "print(df1[df1.kfold==3].target.value_counts())\r\n",
        "print(df1[df1.kfold==4].target.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwcjSQVjaAtz"
      },
      "source": [
        "#now build the model with simple logistic model so the we build the model with one hot encoding \r\n",
        "\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.ensemble import ExtraTreesClassifier\r\n",
        "from sklearn.ensemble import AdaBoostClassifier\r\n",
        "from sklearn.ensemble import GradientBoostingClassifier\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.ensemble import VotingClassifier\r\n",
        "\r\n",
        "#neural network with tensor flow and kearas\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense,Dropout\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8pNMkewaJGG"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,f1_score,accuracy_score,classification_report,roc_auc_score\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J2fbApTlo1F"
      },
      "source": [
        "\r\n",
        "\r\n",
        "md=pd.read_csv(\"/content/drive/MyDrive/Kfold data/fold.csv\")\r\n",
        "md.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rUIRataaMRE"
      },
      "source": [
        "def run(fold):\r\n",
        "  #read the file \r\n",
        "\r\n",
        " md=pd.read_csv(\"/content/drive/MyDrive/Kfold data/fold.csv\")\r\n",
        " #all the feature acept the id and kfold and target\r\n",
        "\r\n",
        " features= [f for f in md.columns if f not in (\"id\",\"target\",\"kfold\")]\r\n",
        " #fill the nan value and cover the all values in nan value \r\n",
        " #i am converting the all coloum value in string \r\n",
        " #it does not matter because it is category value \r\n",
        " for col in features:\r\n",
        "   md.loc[:,col]= md[col].astype(str).fillna(\"None\")\r\n",
        " #get training data using fold \r\n",
        "\r\n",
        " train_md= md[md.kfold !=fold].reset_index(drop=True)\r\n",
        "\r\n",
        "  #validation data using k fold \r\n",
        "\r\n",
        " valid_md=md[md.kfold == fold].reset_index(drop= True)\r\n",
        "\r\n",
        " #now intilize the one hot encoding technique \r\n",
        "\r\n",
        " ohe =OneHotEncoder()\r\n",
        "\r\n",
        " #now full concat the data training and validation\r\n",
        "\r\n",
        " full_data =pd.concat([train_md[features],valid_md[features]],axis=0)\r\n",
        "\r\n",
        "\r\n",
        " #now fit the data \r\n",
        "\r\n",
        " ohe.fit(full_data[features])\r\n",
        "\r\n",
        " #train the data fit and transform \r\n",
        "\r\n",
        " x_train= ohe.transform(train_md[features])\r\n",
        "\r\n",
        " #valid the data \r\n",
        "\r\n",
        " x_valid =ohe.transform(valid_md[features])\r\n",
        "\r\n",
        " #initiate the model\r\n",
        "\r\n",
        " model=LogisticRegression()\r\n",
        "\r\n",
        " model.fit(x_train,train_md.target.values)\r\n",
        "\r\n",
        "\r\n",
        " #predict the validatin data \r\n",
        "\r\n",
        " #we need probility value we are calculating the auc value \r\n",
        "\r\n",
        " #we will use probility of it  \r\n",
        "\r\n",
        " valid_pred= model.predict_proba(x_valid)[:,1]\r\n",
        "\r\n",
        "\r\n",
        " #we get the roc and auc score \r\n",
        "\r\n",
        "\r\n",
        " auc=roc_auc_score(valid_md.target.values,valid_pred)\r\n",
        "\r\n",
        " print(f\"fold = {fold}, auc = {auc}\")\r\n",
        "\r\n",
        " \r\n",
        "if __name__ == \"__main__\":\r\n",
        "  for fold_ in range(5):\r\n",
        "    run(fold=fold_)\r\n",
        "   #run the fold =0\r\n",
        "   #we replace with number \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  \r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOyzz0VYjoiW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSxDEJ2wsvMT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}